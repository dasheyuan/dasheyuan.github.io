<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
      <title>分类 on Chen Yuan&#39;s Blogs </title>
      <generator uri="https://gohugo.io">Hugo</generator>
    <link>http://dasheyuan.com/tags/%E5%88%86%E7%B1%BB/</link>
    <language>en-us</language>
    
    <copyright>Copyright (c) 2016,Chen Yuan; all rights reserved.</copyright>
    <updated>Thu, 12 Feb 2015 00:00:00 UTC</updated>
    
    <item>
      <title>机器学习笔记3 有监督学习 分类 logistic回归</title>
      <link>http://dasheyuan.com/post/2015-02-12</link>
      <pubDate>Thu, 12 Feb 2015 00:00:00 UTC</pubDate>
      
      <guid>http://dasheyuan.com/post/2015-02-12</guid>
      <description>&lt;p&gt;Andrew Ng cs229 Machine Learning 笔记&lt;/p&gt;

&lt;h1 id=&#34;分类问题:662363920bb15b8d466d06a6774c21df&#34;&gt;分类问题&lt;/h1&gt;

&lt;p&gt;分类问题和回归问题不同的是，分类问题的预测值$y$只能取离散值，而非连续值。首先来看一个二类分类问题，预测值$y$只能取0或1。0又被称作负例(negative class)，1被称作正例(positive class)。通常也用&amp;rdquo;-&amp;ldquo;,&amp;rdquo;+&amp;ldquo;符号来表示。对于一个样本集输入$x^{(i)}$，对应的目标值$y^{(i)}$也被为标注(lable)。&lt;/p&gt;

&lt;h2 id=&#34;logistic回归:662363920bb15b8d466d06a6774c21df&#34;&gt;logistic回归&lt;/h2&gt;

&lt;p&gt;也可以用线性回归的方法运用到分类问题上，但是这样做很容易得到不好的结果。稍微改变一下我们的假设函数$h_\theta(x)$，使其的取值在{0,1}范围内：&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>

